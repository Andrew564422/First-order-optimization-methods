# First-order-optimization-methods
***
* This repo contain different types of first order optimization (Momentum, NAG, Adagrad, RMS, Adam) <br>
* these implementations for single variable, and it is easy to generalize it to multi variables <br>
* I made my own implementation for first order optimizers <br>
* After each type, I tested the implementation with different parameters, then plot some plots to see the change in losses and best fit line
